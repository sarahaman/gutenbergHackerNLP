{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, re, requests\n",
    "import cloudscraper\n",
    "scraper = cloudscraper.create_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fanficScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = 'http://fanfiction.net'\n",
    "        self.rate_limit = 1\n",
    "    \n",
    "    #####################\n",
    "    # Tidying Functions #\n",
    "    #####################\n",
    "    \n",
    "    def select_story_text(self, text):\n",
    "        text = text[text.find(\"id=\\'storytext\\'\"):]\n",
    "        text = text[:text.find(\"<SELECT id=chap_select\")]\n",
    "        return text\n",
    "    \n",
    "    def html_cleaner(self, text):\n",
    "        cleaner_regex = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "        cleantext = re.sub(cleaner_regex, '', text)\n",
    "        return cleantext\n",
    "    \n",
    "    ######################\n",
    "    # Pipeline functions #\n",
    "    ######################\n",
    "    \n",
    "    def get_metadata(self, fic_id):\n",
    "        url = '{0}/s/{1}'.format(self.base_url, fic_id)\n",
    "        result = requests.get(url)\n",
    "        metadata = scraper.get(url).text\n",
    "        return metadata\n",
    "    \n",
    "    def get_chapter(self, fic_id, chapter_id):\n",
    "        url = '{0}/s/{1}/{2}'.format(self.base_url, fic_id, chapter_id)\n",
    "        result = requests.get(url)\n",
    "        raw = scraper.get(url).text\n",
    "        story_text = self.select_story_text(raw)\n",
    "        clean_story_text = self.html_cleaner(story_text)\n",
    "        return clean_story_text\n",
    "    \n",
    "    def get_fic(self, fic_id):\n",
    "        raw = self.get_metadata(fic_id)\n",
    "        title = re.search(r\"var title = (.*);\", raw).groups()[0]\n",
    "        num_chapters = int(re.search(r\"Chapters: (.*) - Words\", raw).groups()[0])\n",
    "        \n",
    "        fic = dict.fromkeys(('Title', 'Text'), [])\n",
    "        fic['Title'] = re.sub(r'[^A-Za-z0-9 ]+', '', title)\n",
    "        \n",
    "        time.sleep(self.rate_limit)\n",
    "        for chapter in range(1, num_chapters + 1):\n",
    "            time.sleep(self.rate_limit)\n",
    "            chapter_text = self.get_chapter(fic_id, chapter)\n",
    "            fic['Text'].append(chapter_text)\n",
    "        fic['Text'] = ' '.join(fic['Text'])\n",
    "        return fic\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fic_list = ['13594003', '3157478', '13018460', '5412010', '13784511', '13780235', '3883938', '6466185', '12658932']\n",
    "\n",
    "for i in fic_list:\n",
    "    scrape_fics = fanficScraper()\n",
    "    output_fic = scrape_fics.get_fic(i)\n",
    "    text_title = '{0}.txt'.format(output_fic['Title'])\n",
    "    with open(text_title, 'w', errors = \"ignore\") as f:\n",
    "        f.write(output_fic['Text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
